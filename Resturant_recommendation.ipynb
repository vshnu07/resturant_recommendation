{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+urJMFgofMCzERw/VD6nU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vshnu07/resturant_recommendation/blob/main/Resturant_recommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kcaB9CQ-MjA",
        "outputId": "4210a49a-6308-483c-9022-e584bcd6a021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-18-3593205987.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_orders[col] = pd.to_datetime(df_orders[col], errors='coerce')\n",
            "/tmp/ipython-input-18-3593205987.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_orders[col] = pd.to_datetime(df_orders[col], errors='coerce')\n",
            "/tmp/ipython-input-18-3593205987.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_orders[col] = pd.to_datetime(df_orders[col], errors='coerce')\n",
            "/tmp/ipython-input-18-3593205987.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_orders[col] = pd.to_datetime(df_orders[col], errors='coerce')\n",
            "/tmp/ipython-input-18-3593205987.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_orders[col] = pd.to_datetime(df_orders[col], errors='coerce')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 135288 entries, 0 to 135287\n",
            "Data columns (total 26 columns):\n",
            " #   Column                          Non-Null Count   Dtype         \n",
            "---  ------                          --------------   -----         \n",
            " 0   order_id                        135288 non-null  int64         \n",
            " 1   customer_id                     135288 non-null  object        \n",
            " 2   item_count                      135288 non-null  int64         \n",
            " 3   grand_total                     135288 non-null  float64       \n",
            " 4   payment_mode                    135288 non-null  int64         \n",
            " 5   promo_code                      135288 non-null  object        \n",
            " 6   vendor_discount_amount          135288 non-null  float64       \n",
            " 7   promo_code_discount_percentage  135288 non-null  float64       \n",
            " 8   is_favorite                     135288 non-null  object        \n",
            " 9   is_rated                        135288 non-null  object        \n",
            " 10  vendor_rating                   135288 non-null  float64       \n",
            " 11  driver_rating                   135288 non-null  int64         \n",
            " 12  deliverydistance                135288 non-null  float64       \n",
            " 13  preparationtime                 135288 non-null  float64       \n",
            " 14  delivery_time                   5065 non-null    datetime64[ns]\n",
            " 15  order_accepted_time             86954 non-null   datetime64[ns]\n",
            " 16  driver_accepted_time            46458 non-null   datetime64[ns]\n",
            " 17  ready_for_pickup_time           84248 non-null   datetime64[ns]\n",
            " 18  picked_up_time                  83865 non-null   datetime64[ns]\n",
            " 19  delivered_time                  85741 non-null   datetime64[ns]\n",
            " 20  delivery_date                   35544 non-null   datetime64[ns]\n",
            " 21  vendor_id                       135288 non-null  int64         \n",
            " 22  created_at                      135288 non-null  datetime64[ns]\n",
            " 23  LOCATION_NUMBER                 135288 non-null  int64         \n",
            " 24  LOCATION_TYPE                   135288 non-null  object        \n",
            " 25  CID X LOC_NUM X VENDOR          135288 non-null  object        \n",
            "dtypes: datetime64[ns](8), float64(6), int64(6), object(6)\n",
            "memory usage: 26.8+ MB\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-18-3593205987.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df_orders[col] = pd.to_datetime(df_orders[col], errors='coerce')\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import lightgbm as lgb\n",
        "from math import radians,sin,cos,sqrt,atan2\n",
        "df_orders = pd.read_csv('/content/orders_cleaned_final.csv')\n",
        "df_train_customers=pd.read_csv('/content/cleaned_train_customers.csv')\n",
        "df_train_locations=pd.read_csv('/content/cleaned_train_locations.csv')\n",
        "df_vendors=pd.read_csv('/content/cleaned_vendors.csv')\n",
        "df_test_customers=pd.read_csv('/content/cleaned_test_customers.csv')\n",
        "df_test_locations=pd.read_csv('/content/cleaned_test_locations.csv')\n",
        "\n",
        "#data type conversion\n",
        "date_cols_customer=['created_at','updated_at']\n",
        "for df in [df_train_customers,df_test_customers]:\n",
        "  for col in date_cols_customer:\n",
        "    df[col]=pd.to_datetime(df[col],errors='coerce')\n",
        "date_cols_orders = ['delivery_time', 'order_accepted_time', 'driver_accepted_time','ready_for_pickup_time', 'picked_up_time', 'delivered_time','delivery_date', 'created_at']\n",
        "for col in date_cols_orders:\n",
        "    df_orders[col] = pd.to_datetime(df_orders[col], errors='coerce')\n",
        "date_cols_vendors = ['created_at', 'updated_at']\n",
        "for col in date_cols_vendors:\n",
        "    df_vendors[col] = pd.to_datetime(df_vendors[col], errors='coerce')\n",
        "\n",
        "\n",
        "df_orders.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#feature engineering customer\n",
        "\n",
        "def create_customer_features(df_customers_input):\n",
        "  df = df_customers_input.copy()\n",
        "  max_date = pd.concat([df_train_customers['updated_at'], df_test_customers['updated_at']]).max()\n",
        "  df['account_age_days'] = (max_date - df['created_at']).dt.days\n",
        "  df['updated_since_creation_days'] = (df['updated_at'] - df['created_at']).dt.days\n",
        "\n",
        "\n",
        "\n",
        "  #category of customers\n",
        "  categorical_cols = ['gender', 'status', 'verified', 'language']\n",
        "  df[categorical_cols] = df[categorical_cols].astype('category')\n",
        "  return df\n",
        "\n",
        "\n",
        "df_train_customers_fe = create_customer_features(df_train_customers)\n",
        "print(\"train_customer_features: \\n\",df_train_customers_fe)\n",
        "df_test_customers_fe = create_customer_features(df_test_customers)\n",
        "print(\"test_customer_features: \\n\",df_train_customers_fe)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#feature engineering location\n",
        "\n",
        "\n",
        "def create_location_features(df_locations_input):\n",
        "    df = df_locations_input.copy()\n",
        "    customer_location_counts = df.groupby('customer_id')['location_number'].nunique().reset_index()\n",
        "    customer_location_counts.rename(columns={'location_number': 'num_customer_locations'}, inplace=True)\n",
        "    df = pd.merge(df, customer_location_counts, on='customer_id', how='left')#left join\n",
        "\n",
        "\n",
        "    mode_location_type = df.groupby('customer_id')['location_type'].agg(lambda x: x.mode()[0] if not x.mode().empty else 'Unknown').reset_index()\n",
        "    mode_location_type.rename(columns={'location_type': 'most_frequent_location_type'}, inplace=True)\n",
        "    df = pd.merge(df, mode_location_type, on='customer_id', how='left')\n",
        "\n",
        "\n",
        "    df['location_type'] = df['location_type'].astype('category')\n",
        "    df['most_frequent_location_type'] = df['most_frequent_location_type'].astype('category')\n",
        "    return df\n",
        "\n",
        "\n",
        "df_train_locations_fe = create_location_features(df_train_locations)\n",
        "df_test_locations_fe = create_location_features(df_test_locations)\n",
        "print(\"train_loc\\n\",df_train_locations_fe)\n",
        "print(\"test_loc\\n\",df_test_locations_fe)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#feature engineering vendors\n",
        "\n",
        "def create_vendor_features(df_vendors_input):\n",
        "  df = df_vendors_input.copy()\n",
        "  max_date_vendors = df['updated_at'].max()\n",
        "  df['vendor_age_days'] = (max_date_vendors - df['created_at']).dt.days\n",
        "\n",
        "\n",
        "  #categorey of vendors\n",
        "  df['vendor_category_en'] = df['vendor_category_en'].astype('category')\n",
        "  df['is_open'] = df['is_open'].astype('category')\n",
        "  df['is_haked_delivering'] = df['is_haked_delivering'].astype('category')\n",
        "  df['status'] = df['status'].astype('category')\n",
        "  df['verified'] = df['verified'].astype('category')\n",
        "  df['language'] = df['language'].astype('category')\n",
        "  df['one_click_vendor'] = df['one_click_vendor'].astype('category')\n",
        "  df['device_type'] = df['device_type'].astype('category')\n",
        "  df['display_orders'] = df['display_orders'].astype('category')\n",
        "  df['open_close_flags'] = df['open_close_flags'].astype('category')\n",
        "\n",
        "\n",
        "\n",
        "  def parse_time_string(time_str):\n",
        "    if pd.isna(time_str) or time_str == 'Unknown':\n",
        "      return np.nan\n",
        "    try:\n",
        "      first_time_part = time_str.split('-')[0].strip()\n",
        "      return pd.to_datetime(first_time_part, errors='coerce').hour\n",
        "    except:\n",
        "      return np.nan\n",
        "\n",
        "  df['opening_hour'] = df['OpeningTime'].apply(parse_time_string)\n",
        "  df['opening_hour2'] = df['OpeningTime2'].apply(parse_time_string)\n",
        "\n",
        "\n",
        "  time_columns = [col for col in df.columns if 'from_time' in col or 'to_time' in col]\n",
        "  for col in time_columns:\n",
        "    df[col] = df[col].replace('Unknown', np.nan)\n",
        "  df['num_defined_open_slots'] = df[['sunday_from_time1', 'monday_from_time1', 'tuesday_from_time1','wednesday_from_time1',\n",
        "                                          'thursday_from_time1', 'friday_from_time1','saturday_from_time1']].notna().sum(axis=1)\n",
        "\n",
        "\n",
        "  return df\n",
        "\n",
        "df_vendors_fe = create_vendor_features(df_vendors)\n",
        "\n",
        "print(\"\\nSample customer features (df_train_customers_fe):\")\n",
        "print(df_train_customers_fe[['customer_id', 'gender', 'account_age_days', 'updated_since_creation_days']].head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n",
        "\n",
        "print(\"\\nSample vendor features (df_vendors_fe):\")\n",
        "print(df_vendors_fe[['id', 'vendor_category_en', 'vendor_age_days', 'opening_hour', 'num_defined_open_slots']].head().to_markdown(index=False, numalign=\"left\", stralign=\"left\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OgphCSXljkT",
        "outputId": "619b5767-d970-4337-ecfe-6653b0a6fd5e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_customer_features: \n",
            "       customer_id   gender status verified language          created_at  \\\n",
            "0         TCHWPBT     Male      1        1       EN 2023-02-07 19:16:00   \n",
            "1         ZGFSYCZ     Male      1        1       EN 2023-02-09 12:04:00   \n",
            "2         S2ALZFL     Male      0        1       EN 2023-03-14 18:31:00   \n",
            "3         952DBJQ     Male      1        1       EN 2023-03-15 19:47:00   \n",
            "4         1IX6FXS     Male      1        1       EN 2023-03-15 19:57:00   \n",
            "...           ...      ...    ...      ...      ...                 ...   \n",
            "34598     JAI79PE  Unknown      1        1  Unknown 2025-03-03 13:01:00   \n",
            "34599     TR75VFL  Unknown      1        1  Unknown 2025-03-03 13:22:00   \n",
            "34600     SQMJ08H  Unknown      1        1  Unknown 2025-03-03 13:24:00   \n",
            "34601     9LW9CHN  Unknown      1        1  Unknown 2025-03-03 13:24:00   \n",
            "34602     LBMRK7A  Unknown      1        1  Unknown 2025-03-03 13:31:00   \n",
            "\n",
            "               updated_at  account_age_days  updated_since_creation_days  \n",
            "0     2023-02-07 19:16:00             790.0                          0.0  \n",
            "1     2023-02-09 12:04:00             788.0                          0.0  \n",
            "2     2023-03-14 18:31:00             755.0                          0.0  \n",
            "3     2023-03-15 19:47:00             754.0                          0.0  \n",
            "4     2023-03-15 19:57:00             754.0                          0.0  \n",
            "...                   ...               ...                          ...  \n",
            "34598 2025-03-03 13:02:00              35.0                          0.0  \n",
            "34599 2025-03-03 13:22:00              35.0                          0.0  \n",
            "34600 2025-03-03 13:24:00              35.0                          0.0  \n",
            "34601 2025-03-03 13:28:00              35.0                          0.0  \n",
            "34602 2025-03-03 13:32:00              35.0                          0.0  \n",
            "\n",
            "[34603 rows x 9 columns]\n",
            "test_customer_features: \n",
            "       customer_id   gender status verified language          created_at  \\\n",
            "0         TCHWPBT     Male      1        1       EN 2023-02-07 19:16:00   \n",
            "1         ZGFSYCZ     Male      1        1       EN 2023-02-09 12:04:00   \n",
            "2         S2ALZFL     Male      0        1       EN 2023-03-14 18:31:00   \n",
            "3         952DBJQ     Male      1        1       EN 2023-03-15 19:47:00   \n",
            "4         1IX6FXS     Male      1        1       EN 2023-03-15 19:57:00   \n",
            "...           ...      ...    ...      ...      ...                 ...   \n",
            "34598     JAI79PE  Unknown      1        1  Unknown 2025-03-03 13:01:00   \n",
            "34599     TR75VFL  Unknown      1        1  Unknown 2025-03-03 13:22:00   \n",
            "34600     SQMJ08H  Unknown      1        1  Unknown 2025-03-03 13:24:00   \n",
            "34601     9LW9CHN  Unknown      1        1  Unknown 2025-03-03 13:24:00   \n",
            "34602     LBMRK7A  Unknown      1        1  Unknown 2025-03-03 13:31:00   \n",
            "\n",
            "               updated_at  account_age_days  updated_since_creation_days  \n",
            "0     2023-02-07 19:16:00             790.0                          0.0  \n",
            "1     2023-02-09 12:04:00             788.0                          0.0  \n",
            "2     2023-03-14 18:31:00             755.0                          0.0  \n",
            "3     2023-03-15 19:47:00             754.0                          0.0  \n",
            "4     2023-03-15 19:57:00             754.0                          0.0  \n",
            "...                   ...               ...                          ...  \n",
            "34598 2025-03-03 13:02:00              35.0                          0.0  \n",
            "34599 2025-03-03 13:22:00              35.0                          0.0  \n",
            "34600 2025-03-03 13:24:00              35.0                          0.0  \n",
            "34601 2025-03-03 13:28:00              35.0                          0.0  \n",
            "34602 2025-03-03 13:32:00              35.0                          0.0  \n",
            "\n",
            "[34603 rows x 9 columns]\n",
            "train_loc\n",
            "       customer_id  location_number location_type  latitude  longitude  \\\n",
            "0         02SFNJH                0       Unknown  1.682392 -78.789737   \n",
            "1         02SFNJH                1       Unknown  1.679137   0.766823   \n",
            "2         02SFNJH                2       Unknown -0.498648   0.661241   \n",
            "3         RU43CXC                0          Home  0.100853   0.438165   \n",
            "4         BDFBPRD                0       Unknown  2.523125   0.733464   \n",
            "...           ...              ...           ...       ...        ...   \n",
            "59492     9PP42SA                2       Unknown -0.788515 -78.497721   \n",
            "59493     9PP42SA                3          Home -1.445114   0.072558   \n",
            "59494     9PP42SA                4       Unknown -0.001785   0.431695   \n",
            "59495     HWELAU8                0       Unknown -0.066291 -78.583075   \n",
            "59496     HWELAU8                1       Unknown -0.067043   0.648221   \n",
            "\n",
            "       num_customer_locations most_frequent_location_type  \n",
            "0                           3                     Unknown  \n",
            "1                           3                     Unknown  \n",
            "2                           3                     Unknown  \n",
            "3                           1                        Home  \n",
            "4                           1                     Unknown  \n",
            "...                       ...                         ...  \n",
            "59492                       5                        Home  \n",
            "59493                       5                        Home  \n",
            "59494                       5                        Home  \n",
            "59495                       2                     Unknown  \n",
            "59496                       2                     Unknown  \n",
            "\n",
            "[59497 rows x 7 columns]\n",
            "test_loc\n",
            "       customer_id  location_number location_type    latitude  longitude  \\\n",
            "0         Z59FTQD                0       Unknown  126.032278  -9.106019   \n",
            "1         0JP29SK                0          Home    0.278709 -78.623847   \n",
            "2         0JP29SK                1          Home    0.124485 -78.605621   \n",
            "3         0JP29SK                2       Unknown   -0.113891 -78.577449   \n",
            "4         0JP29SK                3       Unknown   -0.848796   0.136726   \n",
            "...           ...              ...           ...         ...        ...   \n",
            "16712     L9G4OFV                4       Unknown   -0.197722   0.609199   \n",
            "16713     L9G4OFV                5       Unknown   -0.343042   0.626064   \n",
            "16714     FDZFYBA                0          Home   -0.974907  -0.177863   \n",
            "16715     UTKHR1C                0         Other    1.058539   0.001628   \n",
            "16716     3O8LSR3                0         Other   -0.188562   0.827181   \n",
            "\n",
            "       num_customer_locations most_frequent_location_type  \n",
            "0                           1                     Unknown  \n",
            "1                           7                     Unknown  \n",
            "2                           7                     Unknown  \n",
            "3                           7                     Unknown  \n",
            "4                           7                     Unknown  \n",
            "...                       ...                         ...  \n",
            "16712                       6                     Unknown  \n",
            "16713                       6                     Unknown  \n",
            "16714                       1                        Home  \n",
            "16715                       1                       Other  \n",
            "16716                       1                       Other  \n",
            "\n",
            "[16717 rows x 7 columns]\n",
            "\n",
            "Sample customer features (df_train_customers_fe):\n",
            "| customer_id   | gender   | account_age_days   | updated_since_creation_days   |\n",
            "|:--------------|:---------|:-------------------|:------------------------------|\n",
            "| TCHWPBT       | Male     | 790                | 0                             |\n",
            "| ZGFSYCZ       | Male     | 788                | 0                             |\n",
            "| S2ALZFL       | Male     | 755                | 0                             |\n",
            "| 952DBJQ       | Male     | 754                | 0                             |\n",
            "| 1IX6FXS       | Male     | 754                | 0                             |\n",
            "\n",
            "Sample vendor features (df_vendors_fe):\n",
            "| id   | vendor_category_en   | vendor_age_days   | opening_hour   | num_defined_open_slots   |\n",
            "|:-----|:---------------------|:------------------|:---------------|:-------------------------|\n",
            "| 4    | Restaurants          | 798               | 11             | 7                        |\n",
            "| 13   | Restaurants          | 705               | 8              | 7                        |\n",
            "| 20   | Restaurants          | 704               | 8              | 7                        |\n",
            "| 23   | Restaurants          | 702               | 10             | 7                        |\n",
            "| 28   | Restaurants          | 691               | 11             | 7                        |\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#feature engineering orders\n",
        "\n",
        "def create_order_aggregates(df_orders_input):\n",
        "    df = df_orders_input.copy()\n",
        "\n",
        "\n",
        "    #agg of customer order history\n",
        "    customer_order_agg=df.groupby('customer_id').agg(\n",
        "        avg_item_count=('item_count', 'mean'),\n",
        "        avg_grand_total=('grand_total', 'mean'),\n",
        "        total_orders=('order_id', 'nunique'),\n",
        "        most_frequent_payment_mode=('payment_mode', lambda x: x.mode()[0] if not x.mode().empty else -1),\n",
        "        fav_orders_ratio=('is_favorite', lambda x: (x == 'Yes').mean() if x.dtype == 'object' else x.mean()),\n",
        "        rated_orders_ratio=('is_rated', lambda x: (x == 'Yes').mean() if x.dtype == 'object' else x.mean()),\n",
        "        avg_customer_vendor_rating=('vendor_rating', 'mean'),\n",
        "        avg_customer_driver_rating=('driver_rating', 'mean'),\n",
        "        avg_delivery_distance=('deliverydistance', 'mean'),\n",
        "        avg_preparation_time=('preparationtime', 'mean'),\n",
        "        time_since_last_order_days=('created_at', lambda x: (df['created_at'].max() - x.max()).days)).reset_index()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Aggregate vendor order history\n",
        "    vendor_order_agg = df.groupby('vendor_id').agg(\n",
        "        vendor_total_orders=('order_id', 'nunique'),\n",
        "        vendor_avg_item_count=('item_count', 'mean'),\n",
        "        vendor_avg_grand_total=('grand_total', 'mean'),\n",
        "        vendor_avg_delivery_distance=('deliverydistance', 'mean'),\n",
        "        vendor_avg_preparation_time=('preparationtime', 'mean'),\n",
        "        vendor_promo_code_usage_rate=('promo_code', lambda x: (x != 'No Promo').mean())).reset_index()\n",
        "\n",
        "    return customer_order_agg, vendor_order_agg\n",
        "\n",
        "df_customer_order_agg, df_vendor_order_agg = create_order_aggregates(df_orders)\n",
        "print(\"\\nagg customer and vendor\")\n",
        "\n",
        "\n",
        "\n",
        "#distance calculation\n",
        "def haversine(lat1, lon1, lat2, lon2):  #circle distance\n",
        "  R = 6371  #radius of earth in km\n",
        "  lat1, lon1, lat2, lon2 = map(radians, [lat1, lon1, lat2, lon2])\n",
        "  dlat = lat2 - lat1\n",
        "  dlon = lon2 - lon1\n",
        "  a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
        "  c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
        "\n",
        "  distance = R * c\n",
        "  return distance"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1j7XoXOC49F",
        "outputId": "89f8705f-a5b1-4580-a31c-ada22413d3d0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "agg customer and vendor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Training Data(Positive and Negative Samples)\n",
        "\n",
        "# Standardize column name for location number in df_orders\n",
        "df_orders.rename(columns={'LOCATION_NUMBER': 'location_number',\n",
        "                          'LOCATION_TYPE': 'location_type'}, inplace=True)\n",
        "\n",
        "df_train_positive = df_orders[['customer_id', 'location_number', 'vendor_id']].copy()\n",
        "df_train_positive['ordered'] = 1\n",
        "print(f\"\\nPositive samples (from orders): {len(df_train_positive)}\")\n",
        "\n",
        "df_customer_loc_coords = df_train_locations.copy()\n",
        "df_customer_loc_coords = df_customer_loc_coords[['customer_id', 'location_number', 'latitude', 'longitude']]\n",
        "df_customer_loc_coords.rename(columns={'latitude': 'customer_lat', 'longitude': 'customer_lon'}, inplace=True)\n",
        "\n",
        "df_vendor_coords = df_vendors[['id', 'latitude', 'longitude', 'serving_distance']].copy()\n",
        "df_vendor_coords.rename(columns={'id': 'vendor_id', 'latitude': 'vendor_lat', 'longitude': 'vendor_lon'}, inplace=True)\n",
        "\n",
        "all_possible_interactions = []\n",
        "unique_train_customer_locations = df_orders[['customer_id', 'location_number']].drop_duplicates()\n",
        "\n",
        "unique_train_customer_locations = pd.merge(\n",
        "    unique_train_customer_locations,\n",
        "    df_customer_loc_coords,\n",
        "    on=['customer_id', 'location_number'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "for _, row_cust_loc in unique_train_customer_locations.iterrows():\n",
        "    customer_id = row_cust_loc['customer_id']\n",
        "    location_number = row_cust_loc['location_number']\n",
        "    customer_lat = row_cust_loc['customer_lat']\n",
        "    customer_lon = row_cust_loc['customer_lon']\n",
        "\n",
        "    if pd.notna(customer_lat) and pd.notna(customer_lon):\n",
        "        distances = df_vendor_coords.apply(\n",
        "            lambda x: haversine(customer_lat, customer_lon, x['vendor_lat'], x['vendor_lon']),\n",
        "            axis=1\n",
        "        )\n",
        "        eligible_vendors = df_vendor_coords[\n",
        "            (distances <= df_vendor_coords['serving_distance']) | (df_vendor_coords['serving_distance'] == 0)\n",
        "        ]\n",
        "    else:\n",
        "        eligible_vendors = df_vendor_coords.copy()\n",
        "\n",
        "    for vendor_id in eligible_vendors['vendor_id'].unique():\n",
        "        all_possible_interactions.append({\n",
        "            'customer_id': customer_id,\n",
        "            'location_number': location_number,\n",
        "            'vendor_id': vendor_id\n",
        "        })\n",
        "\n",
        "df_all_possible_interactions = pd.DataFrame(all_possible_interactions)\n",
        "print(f\"Total possible customer-location-vendor interactions (after distance filter): {len(df_all_possible_interactions)}\")\n",
        "\n",
        "df_all_possible_interactions['ordered'] = 0\n",
        "df_all_possible_interactions = df_all_possible_interactions.merge(\n",
        "    df_train_positive,\n",
        "    on=['customer_id', 'location_number', 'vendor_id'],\n",
        "    how='left',\n",
        "    suffixes=('_potential', '_actual')\n",
        ")\n",
        "df_all_possible_interactions['ordered'] = df_all_possible_interactions['ordered_actual'].fillna(0).astype(int)\n",
        "df_all_possible_interactions.drop(columns=['ordered_potential', 'ordered_actual'], inplace=True)\n",
        "\n",
        "negatives_pool = df_all_possible_interactions[df_all_possible_interactions['ordered'] == 0]\n",
        "sample_size = min(len(negatives_pool), len(df_train_positive) * 5)\n",
        "df_train_negative_sampled = negatives_pool.sample(n=sample_size, random_state=42)\n",
        "\n",
        "df_train_data = pd.concat([df_train_positive, df_train_negative_sampled]).drop_duplicates().reset_index(drop=True)\n",
        "print(f\"Final training data size (positives + sampled negatives): {len(df_train_data)}\")\n",
        "\n",
        "# Merge all features into the training data\n",
        "df_train_data = pd.merge(df_train_data, df_train_customers_fe, on='customer_id', how='left')\n",
        "df_train_data.drop(columns=['created_at', 'updated_at'], inplace=True)\n",
        "\n",
        "df_train_data = pd.merge(df_train_data, df_train_locations_fe, on=['customer_id', 'location_number'], how='left')\n",
        "df_train_data.rename(columns={'latitude': 'customer_loc_lat', 'longitude': 'customer_loc_lon'}, inplace=True)\n",
        "\n",
        "df_train_data = pd.merge(df_train_data, df_vendors_fe, left_on='vendor_id', right_on='id', how='left')\n",
        "df_train_data.drop(columns=['id', 'created_at_y', 'updated_at_y'], inplace=True,errors='ignore')\n",
        "df_train_data.rename(columns={'latitude': 'vendor_lat_val', 'longitude': 'vendor_lon_val',\n",
        "                              'created_at_x': 'customer_created_at'}, inplace=True)\n",
        "\n",
        "df_train_data = pd.merge(df_train_data, df_customer_order_agg, on='customer_id', how='left')\n",
        "df_train_data = pd.merge(df_train_data, df_vendor_order_agg, on='vendor_id', how='left')\n",
        "\n",
        "df_train_data['customer_vendor_distance'] = df_train_data.apply(\n",
        "    lambda row: haversine(row['customer_loc_lat'], row['customer_loc_lon'],\n",
        "                          row['vendor_lat_val'], row['vendor_lon_val'])\n",
        "    if pd.notna(row['customer_loc_lat']) and pd.notna(row['vendor_lat_val']) else np.nan,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "print(\"\\nAll features merged into training data.\")\n",
        "print(f\"Final training data shape: {df_train_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guswNBuvzHxd",
        "outputId": "c778831e-17e0-427d-be70-02a700d18d03"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Positive samples (from orders): 135288\n",
            "Total possible customer-location-vendor interactions (after distance filter): 99961\n",
            "Final training data size (positives + sampled negatives): 174326\n",
            "\n",
            "All features merged into training data.\n",
            "Final training data shape: (174596, 95)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Model Training\n",
        "\n",
        "target = 'ordered'\n",
        "exclude_cols = [\n",
        "    'customer_id', 'location_number', 'vendor_id', 'customer_created_at',\n",
        "    'OpeningTime', 'OpeningTime2',\n",
        "    'sunday_from_time1', 'sunday_to_time1', 'sunday_from_time2', 'sunday_to_time2',\n",
        "    'monday_from_time1', 'monday_to_time1', 'monday_from_time2', 'monday_to_time2',\n",
        "    'tuesday_from_time1', 'tuesday_to_time1', 'tuesday_from_time2', 'tuesday_to_time2',\n",
        "    'wednesday_from_time1', 'wednesday_to_time1', 'wednesday_from_time2', 'wednesday_to_time2',\n",
        "    'thursday_from_time1', 'thursday_to_time1', 'thursday_from_time2', 'thursday_to_time2',\n",
        "    'friday_from_time1', 'friday_to_time1', 'friday_from_time2', 'friday_to_time2',\n",
        "    'saturday_from_time1', 'saturday_to_time1', 'saturday_from_time2', 'saturday_to_time2',\n",
        "    'customer_loc_lat', 'customer_loc_lon', 'vendor_lat_val', 'vendor_lon_val',\n",
        "    'vendor_tag', 'vendor_tag_name', 'primary_tags',\n",
        "    'created_at', 'updated_at'\n",
        "]\n",
        "\n",
        "features = [col for col in df_train_data.columns if col not in exclude_cols + [target]]\n",
        "\n",
        "X = df_train_data[features]\n",
        "y = df_train_data[target]\n",
        "\n",
        "categorical_features = X.select_dtypes(include='category').columns.tolist()\n",
        "for col in X.select_dtypes(include='object').columns:\n",
        "    if col not in categorical_features:\n",
        "        X[col] = X[col].astype('category')\n",
        "        categorical_features.append(col)\n",
        "\n",
        "print(f\"\\nFeatures selected ({len(features)}): {features}\")\n",
        "print(f\"Categorical features identified ({len(categorical_features)}): {categorical_features}\")\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "print(f\"\\nData split into training ({len(X_train)} samples) and validation ({len(X_val)} samples).\")\n",
        "\n",
        "lgb_clf = lgb.LGBMClassifier(objective='binary', metric='auc', random_state=42)\n",
        "lgb_clf.fit(X_train, y_train,\n",
        "            eval_set=[(X_val, y_val)],\n",
        "            eval_metric='auc',\n",
        "            callbacks=[lgb.early_stopping(10, verbose=False)],\n",
        "            categorical_feature=categorical_features\n",
        "           )\n",
        "\n",
        "print(\"\\nLightGBM model trained successfully.\")\n",
        "print(f\"Validation AUC: {lgb_clf.best_score_['valid_0']['auc']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MSJM7Xa2MSN",
        "outputId": "4a56a038-1ef7-411a-a675-1d8254978ac4"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Features selected (52): ['gender', 'status_x', 'verified_x', 'language_x', 'account_age_days', 'updated_since_creation_days', 'location_type', 'num_customer_locations', 'most_frequent_location_type', 'authentication_id', 'vendor_category_en', 'vendor_category_id', 'delivery_charge', 'serving_distance', 'is_open', 'prepration_time', 'commission', 'is_haked_delivering', 'discount_percentage', 'status_y', 'verified_y', 'rank', 'language_y', 'vendor_rating', 'open_close_flags', 'one_click_vendor', 'country_id', 'city_id', 'device_type', 'display_orders', 'vendor_age_days', 'opening_hour', 'opening_hour2', 'num_defined_open_slots', 'avg_item_count', 'avg_grand_total', 'total_orders', 'most_frequent_payment_mode', 'fav_orders_ratio', 'rated_orders_ratio', 'avg_customer_vendor_rating', 'avg_customer_driver_rating', 'avg_delivery_distance', 'avg_preparation_time', 'time_since_last_order_days', 'vendor_total_orders', 'vendor_avg_item_count', 'vendor_avg_grand_total', 'vendor_avg_delivery_distance', 'vendor_avg_preparation_time', 'vendor_promo_code_usage_rate', 'customer_vendor_distance']\n",
            "Categorical features identified (16): ['gender', 'status_x', 'verified_x', 'language_x', 'location_type', 'most_frequent_location_type', 'vendor_category_en', 'is_open', 'is_haked_delivering', 'status_y', 'verified_y', 'language_y', 'open_close_flags', 'one_click_vendor', 'device_type', 'display_orders']\n",
            "\n",
            "Data split into training (139676 samples) and validation (34920 samples).\n",
            "[LightGBM] [Info] Number of positive: 64176, number of negative: 75500\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.052225 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 3837\n",
            "[LightGBM] [Info] Number of data points in the train set: 139676, number of used features: 45\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.459463 -> initscore=-0.162503\n",
            "[LightGBM] [Info] Start training from score -0.162503\n",
            "\n",
            "LightGBM model trained successfully.\n",
            "Validation AUC: 0.9892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Prediction on Test Set and Submission\n",
        "\n",
        "print(\"\\nPreparing test data for prediction...\")\n",
        "\n",
        "df_test_locations.rename(columns={'LOCATION_NUMBER': 'location_number',\n",
        "                                  'LOCATION_TYPE': 'location_type'}, inplace=True)\n",
        "\n",
        "df_test_customer_locations = df_test_locations[['customer_id', 'location_number']].drop_duplicates().copy()\n",
        "\n",
        "df_test_customer_loc_coords = df_test_locations.copy()\n",
        "df_test_customer_loc_coords = df_test_customer_loc_coords[['customer_id', 'location_number', 'latitude', 'longitude']]\n",
        "df_test_customer_loc_coords.rename(columns={'latitude': 'customer_lat', 'longitude': 'customer_lon'}, inplace=True)\n",
        "\n",
        "df_test_candidates = []\n",
        "for _, row_cust_loc in df_test_customer_locations.iterrows():\n",
        "    customer_id = row_cust_loc['customer_id']\n",
        "    location_number = row_cust_loc['location_number']\n",
        "\n",
        "    customer_coords_row = df_test_customer_loc_coords[\n",
        "        (df_test_customer_loc_coords['customer_id'] == customer_id) &\n",
        "        (df_test_customer_loc_coords['location_number'] == location_number)\n",
        "    ]\n",
        "    if not customer_coords_row.empty:\n",
        "        customer_lat = customer_coords_row['customer_lat'].iloc[0]\n",
        "        customer_lon = customer_coords_row['customer_lon'].iloc[0]\n",
        "    else:\n",
        "        customer_lat = np.nan\n",
        "        customer_lon = np.nan\n",
        "\n",
        "    if pd.notna(customer_lat) and pd.notna(customer_lon):\n",
        "        distances = df_vendor_coords.apply(\n",
        "            lambda x: haversine(customer_lat, customer_lon, x['vendor_lat'], x['vendor_lon']),\n",
        "            axis=1\n",
        "        )\n",
        "        eligible_vendors = df_vendor_coords[\n",
        "            (distances <= df_vendor_coords['serving_distance']) | (df_vendor_coords['serving_distance'] == 0)\n",
        "        ]\n",
        "    else:\n",
        "        eligible_vendors = df_vendor_coords.copy()\n",
        "\n",
        "    for vendor_id in eligible_vendors['vendor_id'].unique():\n",
        "        df_test_candidates.append({\n",
        "            'customer_id': customer_id,\n",
        "            'location_number': location_number,\n",
        "            'vendor_id': vendor_id\n",
        "        })\n",
        "\n",
        "df_test_candidates = pd.DataFrame(df_test_candidates)\n",
        "print(f\"Total test candidate customer-location-vendor interactions: {len(df_test_candidates)}\")\n",
        "\n",
        "df_test_data = pd.merge(df_test_candidates, df_test_customers_fe, on='customer_id', how='left')\n",
        "df_test_data.drop(columns=['created_at', 'updated_at'], inplace=True)\n",
        "\n",
        "df_test_data = pd.merge(df_test_data, df_test_locations_fe, on=['customer_id', 'location_number'], how='left')\n",
        "df_test_data.rename(columns={'latitude': 'customer_loc_lat', 'longitude': 'customer_loc_lon'}, inplace=True)\n",
        "\n",
        "df_test_data = pd.merge(df_test_data, df_vendors_fe, left_on='vendor_id', right_on='id', how='left')\n",
        "df_test_data.drop(columns=[col for col in ['id', 'created_at_y', 'updated_at_y'] if col in df_test_data.columns], inplace=True)\n",
        "df_test_data.rename(columns={'latitude': 'vendor_lat_val', 'longitude': 'vendor_lon_val',\n",
        "                             'created_at_x': 'customer_created_at'}, inplace=True)\n",
        "\n",
        "df_test_data = pd.merge(df_test_data, df_customer_order_agg, on='customer_id', how='left')\n",
        "df_test_data = pd.merge(df_test_data, df_vendor_order_agg, on='vendor_id', how='left')\n",
        "\n",
        "df_test_data['customer_vendor_distance'] = df_test_data.apply(\n",
        "    lambda row: haversine(row['customer_loc_lat'], row['customer_loc_lon'],\n",
        "                          row['vendor_lat_val'], row['vendor_lon_val'])\n",
        "    if pd.notna(row['customer_loc_lat']) and pd.notna(row['vendor_lat_val']) else np.nan,\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "for col in X.columns:\n",
        "    if col in df_test_data.columns:\n",
        "        if df_test_data[col].dtype in ['float64', 'int64']:\n",
        "            df_test_data[col].fillna(0, inplace=True)\n",
        "        elif df_test_data[col].dtype.name == 'category' or df_test_data[col].dtype == 'object':\n",
        "            if 'Unknown' not in df_test_data[col].cat.categories:\n",
        "              df_test_data[col] = df_test_data[col].cat.add_categories(['Unknown'])\n",
        "              df_test_data[col].fillna('Unknown', inplace=True)\n",
        "\n",
        "            df_test_data[col] = df_test_data[col].astype('category')\n",
        "            if not pd.api.types.is_categorical_dtype(df_test_data[col]):\n",
        "                df_test_data[col] = df_test_data[col].astype('category')\n",
        "            train_categories = X_train[col].cat.categories\n",
        "            test_categories = df_test_data[col].cat.categories\n",
        "            missing_in_test = train_categories.difference(test_categories)\n",
        "            if len(missing_in_test) > 0:\n",
        "                df_test_data[col] = df_test_data[col].cat.add_categories(list(missing_in_test))\n",
        "\n",
        "X_test_final = df_test_data[X_train.columns]\n",
        "\n",
        "print(\"\\nPredicting probabilities for test set...\")\n",
        "test_probabilities = lgb_clf.predict_proba(X_test_final)[:, 1]\n",
        "df_test_data['predicted_probability'] = test_probabilities\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS7NZXfq27uH",
        "outputId": "fa919eb5-e4e3-4a9d-adb6-13414034ab81"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Preparing test data for prediction...\n",
            "Total test candidate customer-location-vendor interactions: 35721\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-30-984169402.py:82: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if not pd.api.types.is_categorical_dtype(df_test_data[col]):\n",
            "/tmp/ipython-input-30-984169402.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test_data[col].fillna('Unknown', inplace=True)\n",
            "/tmp/ipython-input-30-984169402.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test_data[col].fillna('Unknown', inplace=True)\n",
            "/tmp/ipython-input-30-984169402.py:82: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if not pd.api.types.is_categorical_dtype(df_test_data[col]):\n",
            "/tmp/ipython-input-30-984169402.py:82: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if not pd.api.types.is_categorical_dtype(df_test_data[col]):\n",
            "/tmp/ipython-input-30-984169402.py:75: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test_data[col].fillna(0, inplace=True)\n",
            "/tmp/ipython-input-30-984169402.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test_data[col].fillna('Unknown', inplace=True)\n",
            "/tmp/ipython-input-30-984169402.py:75: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test_data[col].fillna(0, inplace=True)\n",
            "/tmp/ipython-input-30-984169402.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test_data[col].fillna('Unknown', inplace=True)\n",
            "/tmp/ipython-input-30-984169402.py:82: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if not pd.api.types.is_categorical_dtype(df_test_data[col]):\n",
            "/tmp/ipython-input-30-984169402.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test_data[col].fillna('Unknown', inplace=True)\n",
            "/tmp/ipython-input-30-984169402.py:82: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if not pd.api.types.is_categorical_dtype(df_test_data[col]):\n",
            "/tmp/ipython-input-30-984169402.py:75: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test_data[col].fillna(0, inplace=True)\n",
            "/tmp/ipython-input-30-984169402.py:82: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if not pd.api.types.is_categorical_dtype(df_test_data[col]):\n",
            "/tmp/ipython-input-30-984169402.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test_data[col].fillna('Unknown', inplace=True)\n",
            "/tmp/ipython-input-30-984169402.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test_data[col].fillna('Unknown', inplace=True)\n",
            "/tmp/ipython-input-30-984169402.py:82: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if not pd.api.types.is_categorical_dtype(df_test_data[col]):\n",
            "/tmp/ipython-input-30-984169402.py:75: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test_data[col].fillna(0, inplace=True)\n",
            "/tmp/ipython-input-30-984169402.py:79: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test_data[col].fillna('Unknown', inplace=True)\n",
            "/tmp/ipython-input-30-984169402.py:82: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
            "  if not pd.api.types.is_categorical_dtype(df_test_data[col]):\n",
            "/tmp/ipython-input-30-984169402.py:75: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df_test_data[col].fillna(0, inplace=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Predicting probabilities for test set...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_submission = df_test_data.copy()\n",
        "df_submission['rank'] = df_submission.groupby(['customer_id', 'location_number'])['predicted_probability'].rank(ascending=False, method='first')\n",
        "\n",
        "top_n = 5\n",
        "df_submission_top_n = df_submission[df_submission['rank'] <= top_n].copy()\n",
        "\n",
        "df_submission_top_n['CID X LOC_NUM X VENDOR'] = df_submission_top_n['customer_id'] + ' X ' + \\\n",
        "                                                  df_submission_top_n['location_number'].astype(str) + ' X ' + \\\n",
        "                                                  df_submission_top_n['vendor_id'].astype(str)\n",
        "\n",
        "df_submission_top_n = df_submission_top_n.sort_values(\n",
        "    by=['customer_id', 'location_number', 'rank']\n",
        ")\n",
        "\n",
        "df_final_submission = df_submission_top_n[['CID X LOC_NUM X VENDOR']]\n",
        "\n",
        "submission_filename = 'recommendation_submission.csv'\n",
        "df_final_submission.to_csv(submission_filename, index=False)\n",
        "\n",
        "print(f\"\\nRecommendation engine built and submission file '{submission_filename}' generated successfully.\")\n",
        "print(f\"Submission file head:\\n{df_final_submission.head().to_markdown(index=False, numalign='left', stralign='left')}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yp8zEWwr5ASa",
        "outputId": "4dd2bba6-42db-4839-f022-6a034100e67f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Recommendation engine built and submission file 'recommendation_submission.csv' generated successfully.\n",
            "Submission file head:\n",
            "| CID X LOC_NUM X VENDOR   |\n",
            "|:-------------------------|\n",
            "| 01LAENG X 1 X 43         |\n",
            "| 01LAENG X 1 X 191        |\n",
            "| 01LAENG X 1 X 134        |\n",
            "| 01LAENG X 1 X 676        |\n",
            "| 01LAENG X 2 X 201        |\n"
          ]
        }
      ]
    }
  ]
}